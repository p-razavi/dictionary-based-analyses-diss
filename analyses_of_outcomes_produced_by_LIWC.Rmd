---
title: "Analyses of the Closed-Vocabulary Variables Produced in LIWC"
author: "Pooya Razavi"
date: "last knitted: `r Sys.time()`"
output: 
  html_document:
    theme: cosmo
    highlight: textmate
    toc: TRUE
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---




```{r setup, include=FALSE, warning=FALSE}
#load libraries
package_list <- c("dplyr", "tidyr", "ggplot2", "MetBrewer")
lapply(package_list, require, character.only = TRUE)

#save folder addresses
external_dic_folder <- c("C:/Users/pooya/Dropbox (University of Oregon)/Anger Dissertation/LIWC/Analyzed w external dics/")

internal_dic_folder <- c("C:/Users/pooya/Dropbox (University of Oregon)/Anger Dissertation/LIWC/Analyzed w internal dics/")

#df <- readxl::read_xlsx("C:/Users/pooya/Dropbox (University of Oregon)/Anger Dissertation/Prototype study analysis/ProcessedData_F21_W22_S22_F22.xlsx")

#Function to report correlation
cor_report <- function(cor_output) {
          r <- cor_output[["estimate"]] %>% round(2)
          df <- cor_output[["parameter"]] %>% round(1)
          ci_lb <- (cor_output[["conf.int"]])[1] %>% round(2)
          ci_ub <- (cor_output[["conf.int"]])[2] %>% round(2)
          original_p <- cor_output[["p.value"]] %>% round(3)
          p <- if_else(original_p >= .001, paste0("= ", as.character(original_p)), "< .001")
          
          print(paste0("r(", df, ") = ", r, " [", ci_lb, ", ", ci_ub, "], p ", p))
    }

#Function to report independent-samples t-test
  ind_ttest_report <- function(iv, dv) {
      ttest <- t.test(dv ~ iv)
      effect_size <- effectsize::cohens_d(dv ~ iv, pooled_sd = FALSE)
      t <- ttest[["statistic"]] %>% round(2)
      df <- ttest[["parameter"]] %>% round(1)
      original_p <- ttest[["p.value"]] %>% round(3)
      p <- if_else(original_p >= .001, paste0("= ", as.character(original_p)), "< .001")
      d <- effect_size[1,1] %>% round(2)    
      
      print(paste0("t(", df, ") = ", t, ", p ", p, ", d = ", d))
      
  }
  
#Function to report paired-samples t-test
    paired_ttest_report <- function(t1, t2) {
      ttest <- t.test(Pair(t1, t2) ~ 1)
      effect_size <- effectsize::cohens_d(Pair(t1, t2) ~ 1, pooled_sd = FALSE)
      t <- ttest[["statistic"]] %>% round(2)
      df <- ttest[["parameter"]] %>% round(1)
      original_p <- ttest[["p.value"]] %>% round(3)
      p <- if_else(original_p >= .001, paste0("= ", as.character(original_p)), "< .001")
      d <- effect_size[1,1] %>% round(2)    
      
      print(paste0("t(", df, ") = ", t, ", p ", p, ", d = ", d))
      
  }

#turn off scientific notation
    options(scipen=999)
        
knitr::opts_chunk$set(echo = TRUE)
```

# External Dictionaries

```{r}
#list of .csv LIWC output files
    external_dic_files <- list.files(external_dic_folder)

#create an output df
      external_dic_output <- data.frame(dictionary = NA,
                                        variable = NA,
                                        mean_justified = NA,
                                        sd_justified = NA,
                                        mean_unjustified = NA,
                                        sd_unjustified = NA,
                                        t = NA,
                                        df = NA,
                                        p = NA,
                                        NHST = NA,
                                        d = NA,
                                        d_ci_l = NA,
                                        d_ci_u = NA,
                                        APA = NA)

for (i in 1:length(external_dic_files)) {
  #read in the specific file
  #print(i)
    df <- read.csv(paste0(external_dic_folder, external_dic_files[i]))
  
  #apply the preregistered data exclusion
    #assigning values to factor levels
      df$NarrativeWritten <- as.factor(df$NarrativeWritten)
      df$NarrativeRelevant <- as.factor(df$NarrativeRelevant)
      df$Condition <- as.factor(df$Condition)
      
      levels(df$NarrativeWritten) <- c("No", "Yes")
      levels(df$NarrativeRelevant) <- c("No", "Yes", NA, NA) 
      levels(df$Condition) <- c("justified", "nonjustified", NA)
    
    #drop cases following preregistration
      df1 <- df %>% 
        filter(NarrativeWritten != "No") %>% 
        filter(NarrativeRelevant != "No") %>% 
        filter(!is.na(Condition))
      

    #number of dictionary output columns (the first 7 columns are not from the dictionary analyses)
      n_dic_columns <- ncol(df1) - 7
    
    for (col_number in 1:n_dic_columns) {
      #print(col_number)
          if (mean(df1[,7+col_number]) == 0) {
            #print("Iteration skipped!")
            next
          }
      #extract dictionary and variable (i.e., dictionary component) names
      dictionary <- gsub('LIWC-22 Results - ','', external_dic_files[i]) %>% gsub('.csv', '', .)
      variable <- colnames(df1[7+col_number])
      
      #run t-test
      ttest <- t.test(df1[,7+col_number] ~ df1$Condition)
      effect_size <- effectsize::cohens_d(df1[,7+col_number] ~ df1$Condition, pooled_sd = FALSE)
      t <- ttest[["statistic"]] %>% round(2)
      df <- ttest[["parameter"]] %>% round(1)
      original_p <- ttest[["p.value"]] %>% round(3)
      p <- if_else(original_p >= .001, paste0("= ", as.character(original_p)), "< .001")
      NHST <- if_else(original_p >= .05, "null", 
                      if_else(original_p >= .005, "sugg.", "sig."))
      d <- effect_size[1,1] %>% round(2)  
      d_ci_l <- effect_size[1,3] %>% round(2)  
      d_ci_u <- effect_size[1,4] %>% round(2)  
      
      #descriptives
      mean_justified <- (ttest[["estimate"]])[[1]] %>% round(2)
      mean_unjustified <- (ttest[["estimate"]])[[2]] %>% round(2)
      sd_justified <- (df1 %>% filter(Condition == "justified") %>% select((7+col_number)) %>% 
                         psych::describe() %>% select(sd))[1,1] %>% round(2)
      sd_unjustified <- (df1 %>% filter(Condition == "nonjustified") %>% select((7+col_number)) %>% 
                           psych::describe() %>% select(sd))[1,1] %>% round(2)
      APA <- paste0("t(", df, ") = ", t, ", p ", p, ", d = ", d)
      
      #add to output
      external_dic_output <- rbind(external_dic_output,
                                   cbind(dictionary, variable, mean_justified, sd_justified, mean_unjustified, sd_unjustified, t, df, p, NHST, d, d_ci_l, d_ci_u, APA))
    }  
      
}
      
#Clean up the output table
      rownames(external_dic_output) <- NULL
      
      external_dic_output <- external_dic_output[-1,] 
        
```

## Table: All Comparisons

```{r}
external_dic_output %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable() %>% kableExtra::kable_styling()

#save as an excel file (for the manuscript)
  #external_dic_output %>% 
  #mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
  #       Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")"),
  #       ttest_APA = gsub(", d.*", "", APA), #this removed the d results from APA results
  #       d_w_ci = paste0(d, " [", d_ci_l, ", ", d_ci_u, "]")) %>% 
  #select(dictionary, variable, Justified, Unjustified, ttest_APA, d_w_ci) %>% 
  #writexl::write_xlsx("external_dic_comparisons_02.xlsx")
```

## Table: Significant Differences

```{r}

external_dic_output %>%
  filter(NHST == "sig.") %>% 
  arrange(desc(abs(as.numeric(d)))) %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()
```


## Table: Suggestive Differences

```{r}
external_dic_output %>%
  filter(NHST == "sugg.") %>% 
  arrange(desc(abs(as.numeric(d)))) %>% 
  select(dictionary, variable, mean_justified, mean_unjustified, APA) %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()
```

## Table: Null Results

```{r}
external_dic_output %>%
  filter(NHST == "null") %>% 
  arrange(desc(abs(as.numeric(d)))) %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()
```

### Moral Foundation Results

```{r}
df_MFT2 <- read.csv(paste0(external_dic_folder, (list.files(external_dic_folder))[4]))

df_MFT2 <- df_MFT2 %>% 
                mutate(MFT_sum = rowSums(across(Care_Virtue:Sanctity_Vice)))

  #apply the preregistered data exclusion
    #assigning values to factor levels
      df_MFT2$NarrativeWritten <- as.factor(df_MFT2$NarrativeWritten)
      df_MFT2$NarrativeRelevant <- as.factor(df_MFT2$NarrativeRelevant)
      df_MFT2$Condition <- as.factor(df_MFT2$Condition)
      
      levels(df_MFT2$NarrativeWritten) <- c("No", "Yes")
      levels(df_MFT2$NarrativeRelevant) <- c("No", "Yes", NA, NA) 
      levels(df_MFT2$Condition) <- c("justified", "nonjustified", NA)
    
    #drop cases following preregistration
      df_MFT2 <- df_MFT2 %>% 
        filter(NarrativeWritten != "No") %>% 
        filter(NarrativeRelevant != "No") %>% 
        filter(!is.na(Condition))

psych::describeBy(df_MFT2$MFT_sum, group = df_MFT2$Condition)      
ind_ttest_report(df_MFT2$Condition, df_MFT2$MFT_sum)
effectsize::cohens_d(df_MFT2$MFT_sum, df_MFT2$Condition)

```

### Moral Justification Outcome Summary

```{r}
all_output %>% 
  filter(dictionary == "Moral Justification") %>% 
  filter(variable != "Moral_Emotions_General") %>% 
  mutate(avg_d = (as.numeric(mean_justified) + as.numeric(mean_unjustified))/2) %>% 
  select(avg_d) %>% psych::describe()
  

```


## Figure: Effects Larger than d = .20

```{r}
ext_dic_df_plot <- external_dic_output %>%
                      filter(abs(as.numeric(d)) >= .2) %>% 
                      #filter(dictionary != "Stereotype Content") %>% 
                      arrange(desc(abs(as.numeric(d)))) %>% 
                      mutate(effect = as.numeric(d),
                             lowerbound = as.numeric(d_ci_l),
                             upperbound = as.numeric(d_ci_u),
                             construct = paste0(gsub("_", " ", variable), " (", dictionary, ")"),
                             color = if_else(as.numeric(d) > 0, "darkgreen", "darkred")) %>% 
                      mutate(construct = forcats::fct_reorder(construct, as.numeric(d))) %>% 
                      select(construct, effect, lowerbound, upperbound, color)



ggplot(ext_dic_df_plot, aes(x = construct, y = effect)) +
  geom_errorbar(aes(ymin = lowerbound, ymax = upperbound), width = 0.15, color = "darkgrey") +
  geom_point(color = ext_dic_df_plot$color) +
  geom_hline(yintercept = 0, color = "lightblue", linetype = "dashed") +
  geom_text(label = ext_dic_df_plot$effect, vjust = -0.6, size = 3, color = ext_dic_df_plot$color) +
  labs(x = "", y = "Cohen's d (Justified - Unjustified Anger)") +
  coord_flip() +
  theme_minimal(base_size = 10)
```

# Internal Dictionaries

```{r}
#list of .csv LIWC output files
    internal_dic_files <- list.files(internal_dic_folder)

#create an output df
      internal_dic_output <- data.frame(dictionary = NA,
                                        variable = NA,
                                        mean_justified = NA,
                                        sd_justified = NA,
                                        mean_unjustified = NA,
                                        sd_unjustified = NA,
                                        t = NA,
                                        df = NA,
                                        p = NA,
                                        NHST = NA,
                                        d = NA,
                                        d_ci_l = NA,
                                        d_ci_u = NA,
                                        APA = NA)

for (i in 1:length(internal_dic_files)) {
  #read in the specific file
  #print(i)
    df <- read.csv(paste0(internal_dic_folder, internal_dic_files[i]))
  
  #apply the preregistered data exclusion
    #assigning values to factor levels
      df$NarrativeWritten <- as.factor(df$NarrativeWritten)
      df$NarrativeRelevant <- as.factor(df$NarrativeRelevant)
      df$Condition <- as.factor(df$Condition)
      
      levels(df$NarrativeWritten) <- c("No", "Yes")
      levels(df$NarrativeRelevant) <- c("No", "Yes", NA, NA) 
      levels(df$Condition) <- c("justified", "nonjustified", NA)
    
    #drop cases following preregistration
      df1 <- df %>% 
        filter(NarrativeWritten != "No") %>% 
        filter(NarrativeRelevant != "No") %>% 
        filter(!is.na(Condition))
      

    #number of dictionary output columns (the first 7 columns are not from the dictionary analyses)
      n_dic_columns <- ncol(df1) - 7
    
    for (col_number in 1:n_dic_columns) {
      #print(col_number)
          if (mean(df1[,7+col_number]) == 0) {
            #print("Iteration skipped!")
            next
          }
      #extract dictionary and variable (i.e., dictionary component) names
      dictionary <- gsub('LIWC-22 Results - Internal - ','', internal_dic_files[i]) %>% gsub('.csv', '', .)
      variable <- colnames(df1[7+col_number])
      
      #run t-test
      ttest <- t.test(df1[,7+col_number] ~ df1$Condition)
      effect_size <- effectsize::cohens_d(df1[,7+col_number] ~ df1$Condition, pooled_sd = FALSE)
      t <- ttest[["statistic"]] %>% round(2)
      df <- ttest[["parameter"]] %>% round(1)
      original_p <- ttest[["p.value"]] %>% round(3)
      p <- if_else(original_p >= .001, paste0("= ", as.character(original_p)), "< .001")
      NHST <- if_else(original_p >= .05, "null", 
                      if_else(original_p >= .005, "sugg.", "sig."))
      d <- effect_size[1,1] %>% round(2)  
      d_ci_l <- effect_size[1,3] %>% round(2)  
      d_ci_u <- effect_size[1,4] %>% round(2)  
      
      #descriptives
      mean_justified <- (ttest[["estimate"]])[[1]] %>% round(2)
      mean_unjustified <- (ttest[["estimate"]])[[2]] %>% round(2)
      sd_justified <- (df1 %>% filter(Condition == "justified") %>% select((7+col_number)) %>% 
                         psych::describe() %>% select(sd))[1,1] %>% round(2)
      sd_unjustified <- (df1 %>% filter(Condition == "nonjustified") %>% select((7+col_number)) %>% 
                           psych::describe() %>% select(sd))[1,1] %>% round(2)
      APA <- paste0("t(", df, ") = ", t, ", p ", p, ", d = ", d)
      
      #add to output
      internal_dic_output <- rbind(internal_dic_output,
                                   cbind(dictionary, variable, mean_justified, sd_justified, mean_unjustified, sd_unjustified, t, df, p, NHST, d, d_ci_l, d_ci_u, APA))
    }  
      
}
      
#Clean up the output table
      rownames(internal_dic_output) <- NULL
      
      internal_dic_output <- internal_dic_output[-1,] 
        
```

## Summary Dictionaries

### All Results

```{r}
internal_dic_output %>% 
  filter(dictionary == "Summary") %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()

#save as an excel file (for the manuscript)
  #internal_dic_output %>%  
  #filter(dictionary == "Summary") %>%
  #mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
  #       Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")"),
  #       ttest_APA = gsub(", d.*", "", APA), #this removed the d results from APA results
  #       d_w_ci = paste0(d, " [", d_ci_l, ", ", d_ci_u, "]")) %>% 
  #select(dictionary, variable, Justified, Unjustified, ttest_APA, d_w_ci) %>% 
  #writexl::write_xlsx("internal_summary_dic_comparisons_02.xlsx")
```


### Ordered Based on Effect Size

```{r}
internal_dic_output %>% 
  filter(dictionary == "Summary") %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  arrange(desc(abs(as.numeric(d)))) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()
```


## Basic Dictionaries

### All Results

```{r}
internal_dic_output %>% 
  filter(dictionary == "Basic Dics") %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()

#save as an excel file (for the manuscript)
  #internal_dic_output %>%  
  #filter(dictionary == "Basic Dics") %>%
  #mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
  #       Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")"),
  #       ttest_APA = gsub(", d.*", "", APA), #this removed the d results from APA results
  #       d_w_ci = paste0(d, " [", d_ci_l, ", ", d_ci_u, "]")) %>% 
  #select(dictionary, variable, Justified, Unjustified, ttest_APA, d_w_ci) %>% 
  #writexl::write_xlsx("internal_basic_dic_comparisons_02.xlsx")
```


### Ordered Based on Effect Size

```{r}
internal_dic_output %>% 
  filter(dictionary == "Basic Dics") %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  arrange(desc(abs(as.numeric(d)))) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()
```

### Figure: Effects Larger than d = .20

Since there are only two differences with d >= .20 among the "expanded" dictionaries, they are all included in this graph together with the "basic" dictionary results.
```{r}
int_basicexpanddic_df_plot <- internal_dic_output %>% 
                      filter(dictionary != "Summary") %>% 
                      filter(abs(as.numeric(d)) >= .2) %>% 
                      arrange(desc(abs(as.numeric(d)))) %>% 
                      mutate(effect = as.numeric(d),
                             lowerbound = as.numeric(d_ci_l),
                             upperbound = as.numeric(d_ci_u),
                             construct = paste0(gsub("_", " ", variable), " (", dictionary, ")"),
                             color = if_else(as.numeric(d) > 0, "darkgreen", "darkred")) %>% 
                    #mutate(construct = forcats::fct_reorder(construct, as.numeric(d))) %>%
                      select(construct, effect, lowerbound, upperbound, color)

#manually correct the construct labels
int_basicexpanddic_df_plot$construct <- c("Emotion Words (Overall)", "Negative Emotions (Overall)", "Cognitive Processing: Differentiation", "Negative Emotions: Anger", "Social Processes (Overall)", "Cognitive Processing (Overall)", "Cognitive Processing: Discrepancy", "Social Referents (Overall)", "Cognition (Overall)", "Drives (Overall)", "Social Behavior (Overall)", "Drives: Affiliation", "Cognition: All-or-none", "Social Behavior: Communication", "States: Want", "Affect (Overall)", "Physical: Sexual")
    
  int_basicexpanddic_df_plot <- int_basicexpanddic_df_plot %>% 
                                  mutate(construct = forcats::fct_reorder(construct, as.numeric(effect)))


ggplot(int_basicexpanddic_df_plot, aes(x = construct, y = effect)) +
  geom_errorbar(aes(ymin = lowerbound, ymax = upperbound), width = 0.15, color = "darkgrey") +
  geom_point(color = int_basicexpanddic_df_plot$color) +
  geom_hline(yintercept = 0, color = "lightblue", linetype = "dashed") +
  geom_text(label = int_basicexpanddic_df_plot$effect, vjust = -0.6, size = 3, color = int_basicexpanddic_df_plot$color) +
  labs(x = "", y = "Cohen's d (Justified - Unjustified Anger)") +
  coord_flip() +
  theme_minimal(base_size = 10)
```

## Expanded Dictionaries

### All Results

```{r}
internal_dic_output %>% 
  filter(dictionary == "Expanded Dics") %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()

#save as an excel file (for the manuscript)
  #internal_dic_output %>%  
  #filter(dictionary == "Expanded Dics") %>%
  #mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
  #       Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")"),
  #       ttest_APA = gsub(", d.*", "", APA), #this removed the d results from APA results
  #       d_w_ci = paste0(d, " [", d_ci_l, ", ", d_ci_u, "]")) %>% 
  #select(dictionary, variable, Justified, Unjustified, ttest_APA, d_w_ci) %>%  
  #writexl::write_xlsx("internal_expanded_dic_comparisons_02.xlsx")
```


### Ordered Based on Effect Size

```{r}
internal_dic_output %>% 
  filter(dictionary == "Expanded Dics") %>% 
  mutate(Justified = paste0(mean_justified, " (", sd_justified, ")"),
         Unjustified = paste0(mean_unjustified, " (", sd_unjustified, ")")) %>% 
  arrange(desc(abs(as.numeric(d)))) %>% 
  select(dictionary, variable, Justified, Unjustified, APA) %>% 
  knitr::kable()
```


### Figure: All Effects (|d| >= .20)

```{r}
internal_sum_algo <- internal_dic_output %>% 
                        filter(variable %in% c("Analytic", "Clout")) %>% 
                                        mutate(effect = as.numeric(d),
                                               lowerbound = as.numeric(d_ci_l),
                                               upperbound = as.numeric(d_ci_u),
                                               construct = paste0(gsub("_", " ", variable), " (", dictionary, ")"),
                                               color = if_else(as.numeric(d) > 0, "darkgreen", "darkred")) %>% 
                                      #mutate(construct = forcats::fct_reorder(construct, as.numeric(d))) %>%
                                        select(construct, effect, lowerbound, upperbound, color) 
internal_sum_algo$construct <- c("Analytical Thinking (LIWC)", "Clout (LIWC)")




int_basicexpanddic_df_plot <- int_basicexpanddic_df_plot %>% 
        mutate(construct = paste0(gsub("\\(Overall\\)", "- Overall", int_basicexpanddic_df_plot$construct), " (LIWC)")) 


all_dic_df_plot <- rbind(ext_dic_df_plot, int_basicexpanddic_df_plot, internal_sum_algo) %>% 
                        mutate(construct = forcats::fct_reorder(construct, effect))


all_dictionary_diff <- ggplot(all_dic_df_plot, aes(x = construct, y = effect)) +
                          geom_errorbar(aes(ymin = lowerbound, ymax = upperbound), width = 0.25, size = 0.75, color = "darkgrey") +
                          geom_point(color = all_dic_df_plot$color, size = 1.75) +
                          geom_hline(yintercept = 0, color = "darkblue", linetype = "dashed") +
                          geom_text(label = sprintf("%0.2f", round(all_dic_df_plot$effect, 2)), vjust = -0.6, size = 3.5, color = all_dic_df_plot$color) +
                          labs(x = "Construct (Dictionary)", 
                               y = expression("Cohen's" ~italic(d)~ "(Justified - Unjustified Anger)")) +
                          coord_flip() +
                          theme_minimal(base_size = 15) +
                          theme(text=element_text(family = "serif"))

all_dictionary_diff
#ggsave(plot = all_dictionary_diff, width = 10, height = 10.5, dpi = 300, filename = "all_dictionary_differences_p.png")
```

# Relation between base rates (M) and effect sizes (d)


```{r}
#combine the internal and external findings
all_output <- rbind(internal_dic_output, external_dic_output) %>% 
                    mutate(threshold = if_else(as.numeric(d) >= .2, "above", "below")) %>% 
                    mutate(average_percentage = (as.numeric(mean_justified) + as.numeric(mean_unjustified))/2) %>% 
                    filter(dictionary != "Summary" & dictionary != "Extended MFT") 

psych::describeBy(all_output$average_percentage, group = all_output$threshold)

#correlation between average percentage and effect size
    cor.test(all_output$average_percentage, abs(as.numeric(all_output$d)), method = c( "pearson")) 
    cor.test(all_output$average_percentage, abs(as.numeric(all_output$d)), method = c( "spearman")) 


```

